{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802a320d",
   "metadata": {},
   "source": [
    "# v2-Create-Custom-Agent-Enhanced\n",
    "\n",
    "åŸºäºv1å¢å¼ºç‰ˆï¼Œæ–°å¢JDèŒä½æè¿°è§£æï¼š\n",
    "- åŸºäºåŸç‰ˆv2çš„æ‰€æœ‰åŠŸèƒ½\n",
    "- é›†æˆèŒä½éœ€æ±‚è§£æ\n",
    "- é’ˆå¯¹æ€§æŠ€æœ¯æé—®\n",
    "\n",
    "å¯¹åº”åŸç‰ˆï¼š`v2-Create-Custom-Agent.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9679e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DeepSeek API Key å·²é…ç½®\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "# æ£€æŸ¥DeepSeek API Key\n",
    "if os.getenv('DEEPSEEK_API_KEY'):\n",
    "    print(\"âœ… DeepSeek API Key å·²é…ç½®\")\n",
    "else:\n",
    "    print(\"âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®DEEPSEEK_API_KEY\")\n",
    "    raise ValueError(\"DeepSeek API Keyæœªé…ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28598f77",
   "metadata": {},
   "source": [
    "## Load the LLM åŠ è½½LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdec4582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  ä½¿ç”¨DeepSeekæ¨¡å‹è¿›è¡ŒJDè§£æé¢è¯•\n",
      "ğŸ‡¨ğŸ‡³ æ”¯æŒä¸­æ–‡èŒä½æè¿°ç†è§£\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ä½¿ç”¨DeepSeekä½œä¸ºLLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    openai_api_base=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ§  ä½¿ç”¨DeepSeekæ¨¡å‹è¿›è¡ŒJDè§£æé¢è¯•\")\n",
    "print(\"ğŸ‡¨ğŸ‡³ æ”¯æŒä¸­æ–‡èŒä½æè¿°ç†è§£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3633c1f3",
   "metadata": {},
   "source": [
    "## Define Tools å®šä¹‰å·¥å…·ï¼ˆç»§æ‰¿v1ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "708e01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "@tool\n",
    "def generate_unique_timestamp():\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå”¯ä¸€çš„æ—¶é—´æˆ³ã€‚è¾“å…¥å§‹ç»ˆä¸ºç©ºå­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "    Returns:\n",
    "        int: å”¯ä¸€çš„æ—¶é—´æˆ³ï¼Œä»¥æ¯«ç§’ä¸ºå•ä½ã€‚\n",
    "    \"\"\"\n",
    "    timestamp = int(time.time() * 1000)\n",
    "    return timestamp\n",
    "\n",
    "@tool\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"\n",
    "    æ ¹æ®ç»™å®šçš„æ–‡ä»¶å¤¹ååˆ›å»ºæ–‡ä»¶å¤¹ã€‚\n",
    "\n",
    "    Args:\n",
    "        folder_name (str): è¦åˆ›å»ºçš„æ–‡ä»¶å¤¹çš„åç§°ã€‚\n",
    "\n",
    "    Returns:\n",
    "        str: åˆ›å»ºçš„æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        folder_path = os.path.join(\"chat_history\", folder_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        return os.path.abspath(folder_path)\n",
    "    except OSError as e:\n",
    "        print(f\"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥ï¼š{e}\")\n",
    "        return None\n",
    "\n",
    "@tool\n",
    "def delete_temp_folder():\n",
    "    \"\"\"\n",
    "    åˆ é™¤ chat_history æ–‡ä»¶å¤¹ä¸‹çš„ temp æ–‡ä»¶å¤¹ã€‚è¾“å…¥å§‹ç»ˆä¸ºç©ºå­—ç¬¦ä¸²ã€‚\n",
    "\n",
    "    Returns:\n",
    "        bool: å¦‚æœæˆåŠŸåˆ é™¤åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚\n",
    "    \"\"\"\n",
    "    temp_folder = \"chat_history/temp\"\n",
    "    try:\n",
    "        if os.path.exists(temp_folder):\n",
    "            shutil.rmtree(temp_folder)\n",
    "            print(\"æˆåŠŸåˆ é™¤ temp æ–‡ä»¶å¤¹ã€‚\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"åˆ é™¤ temp æ–‡ä»¶å¤¹å¤±è´¥ï¼š{e}\")\n",
    "        return False\n",
    "\n",
    "@tool\n",
    "def copy_chat_history(interview_id: str) -> str:\n",
    "    \"\"\"\n",
    "    å°† chat_history/temp æ–‡ä»¶å¤¹ä¸­çš„ chat_history.txt æ–‡ä»¶å¤åˆ¶åˆ°æŒ‡å®šé¢è¯•IDæ–‡ä»¶å¤¹ä¸­ã€‚\n",
    "    \"\"\"\n",
    "    temp_folder = os.path.join(\"chat_history\", \"temp\")\n",
    "    interview_folder = os.path.join(\"chat_history\", interview_id)\n",
    "\n",
    "    if not os.path.exists(interview_folder):\n",
    "        return f\"é¢è¯•IDä¸º {interview_id} çš„æ–‡ä»¶å¤¹ä¸å­˜åœ¨ã€‚æ— æ³•å®Œæˆå¤åˆ¶æ“ä½œã€‚\"\n",
    "\n",
    "    source_file = os.path.join(temp_folder, 'chat_history.txt')\n",
    "    destination_file = os.path.join(interview_folder, 'chat_history.txt')\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(source_file):\n",
    "            shutil.copyfile(source_file, destination_file)\n",
    "            return f\"å·²å°† chat_history.txt å¤åˆ¶åˆ°é¢è¯•IDä¸º {interview_id} çš„æ–‡ä»¶å¤¹ä¸­ã€‚\"\n",
    "        else:\n",
    "            return \"ä¸´æ—¶èŠå¤©è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ã€‚\"\n",
    "    except Exception as e:\n",
    "        return f\"å¤åˆ¶æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def read_chat_history(interview_id: str) -> str:\n",
    "    \"\"\"\n",
    "    è¯»å–æŒ‡å®šé¢è¯•IDæ–‡ä»¶å¤¹ä¸‹çš„èŠå¤©è®°å½•å†…å®¹ã€‚\n",
    "    \"\"\"\n",
    "    interview_folder = os.path.join(\"chat_history\", interview_id)\n",
    "\n",
    "    if not os.path.exists(interview_folder):\n",
    "        return f\"é¢è¯•IDä¸º {interview_id} çš„æ–‡ä»¶å¤¹ä¸å­˜åœ¨ã€‚æ— æ³•è¯»å–èŠå¤©è®°å½•ã€‚\"\n",
    "\n",
    "    chat_history_file = os.path.join(interview_folder, 'chat_history.txt')\n",
    "    try:\n",
    "        if os.path.exists(chat_history_file):\n",
    "            with open(chat_history_file, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        else:\n",
    "            return \"èŠå¤©è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ã€‚\"\n",
    "    except Exception as e:\n",
    "        return f\"è¯»å–èŠå¤©è®°å½•æ—¶å‡ºé”™: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def generate_markdown_file(interview_id: str, interview_feedback: str) -> str:\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆé¢è¯•æŠ¥å‘Šçš„Markdownæ–‡ä»¶ã€‚\n",
    "    \"\"\"\n",
    "    interview_folder = os.path.join(\"chat_history\", interview_id)\n",
    "\n",
    "    if not os.path.exists(interview_folder):\n",
    "        return f\"é¢è¯•IDä¸º {interview_id} çš„æ–‡ä»¶å¤¹ä¸å­˜åœ¨ã€‚æ— æ³•ç”Ÿæˆ Markdown æ–‡ä»¶ã€‚\"\n",
    "\n",
    "    markdown_file_path = os.path.join(interview_folder, \"é¢è¯•æŠ¥å‘Š.md\")\n",
    "\n",
    "    try:\n",
    "        with open(markdown_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(\"# é¢è¯•æŠ¥å‘Š\\n\\n\")\n",
    "            file.write(\"## é¢è¯•åé¦ˆï¼š\\n\\n\")\n",
    "            file.write(interview_feedback)\n",
    "            file.write(\"\\n\\n\")\n",
    "\n",
    "            # æ·»åŠ é¢è¯•è®°å½•\n",
    "            chat_history_file_path = os.path.join(interview_folder, \"chat_history.txt\")\n",
    "            if os.path.exists(chat_history_file_path):\n",
    "                file.write(\"## é¢è¯•è®°å½•ï¼š\\n\\n\")\n",
    "                with open(chat_history_file_path, 'r', encoding='utf-8') as chat_file:\n",
    "                    for line in chat_file:\n",
    "                        file.write(line.rstrip('\\n') + '\\n\\n')\n",
    "\n",
    "        return f\"å·²ç”Ÿæˆ Markdown æ–‡ä»¶: {markdown_file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"ç”Ÿæˆ Markdown æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bdd82-6f72-4486-a6f9-349b488d38aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9d853-bf7a-4d4f-9589-f6d4f27a1f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a16250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [generate_unique_timestamp, create_folder, copy_chat_history, read_chat_history, generate_markdown_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457fefe-98f9-41b6-9bba-86f3d043213a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caacddf9",
   "metadata": {},
   "source": [
    "## v2æ–°å¢ï¼šJDèŒä½æè¿°è§£æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33fc3edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²å­˜å‚¨æœ€ç»ˆ JSON æ–‡ä»¶åˆ° data/jd.json\n",
      "âœ… æˆåŠŸè¯»å–JDä¿¡æ¯\n",
      "èŒä½ï¼šAIå·¥ç¨‹å¸ˆ\n",
      "ä¸“ä¸šæŠ€èƒ½/çŸ¥è¯†/èƒ½åŠ›ï¼š['Pythonå¼€å‘', 'æœºå™¨å­¦ä¹ æ¡†æ¶(TensorFlow, PyTorch)', 'LangChain', 'å‘é‡æ•°æ®åº“', 'Agentå¼€å‘', 'DeepSeekç­‰å¤§è¯­è¨€æ¨¡å‹', 'AIåº”ç”¨ç³»ç»Ÿå¼€å‘', 'æ™ºèƒ½å¯¹è¯æœºå™¨äººè®¾è®¡ä¸å®ç°', 'æ¨¡å‹æ€§èƒ½ä¼˜åŒ–', 'ç”¨æˆ·ä½“éªŒä¼˜åŒ–', 'AIæŠ€æœ¯è½åœ°']\n"
     ]
    }
   ],
   "source": [
    "# è§£æJDæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦é‡æ–°è§£æï¼‰\n",
    "from utils_enhanced import parse_jd_to_json, read_json\n",
    "\n",
    "# å¯é€‰ï¼šé‡æ–°è§£æJD\n",
    "jd_file_path = \"data/jd.txt\"\n",
    "jd_json_file_path = parse_jd_to_json(llm, jd_file_path)\n",
    "\n",
    "# è¯»å–å·²è§£æçš„JD\n",
    "jd_json_file_path = \"data/jd.json\"\n",
    "if os.path.exists(jd_json_file_path):\n",
    "    jd_dict = read_json(jd_json_file_path)\n",
    "    job_title = jd_dict.get('åŸºæœ¬ä¿¡æ¯', {}).get('èŒä½', 'Pythonå·¥ç¨‹å¸ˆ')\n",
    "    job_key_skills = jd_dict.get('ä¸“ä¸šæŠ€èƒ½/çŸ¥è¯†/èƒ½åŠ›', [])\n",
    "    print(f\"âœ… æˆåŠŸè¯»å–JDä¿¡æ¯\")\n",
    "    print(f\"èŒä½ï¼š{job_title}\")\n",
    "    print(f\"ä¸“ä¸šæŠ€èƒ½/çŸ¥è¯†/èƒ½åŠ›ï¼š{job_key_skills}\")\n",
    "else:\n",
    "    print(\"âš ï¸  JDæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®\")\n",
    "    job_title = \"Pythonå·¥ç¨‹å¸ˆ (AIåº”ç”¨æ–¹å‘)\"\n",
    "    job_key_skills = [\"Python\", \"AI\", \"æœºå™¨å­¦ä¹ \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4135aa-4e74-46fd-a100-695d1fc66c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cd62f-1715-4062-81bd-b6ffe554f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edbb1b5",
   "metadata": {},
   "source": [
    "## Create Enhanced Prompt åˆ›å»ºv2å¢å¼ºæç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3542c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "## Role and Goals\n",
    "- ä½ æ˜¯æ‰€æ‹›å²—ä½\"{job_title}\"çš„æŠ€æœ¯ä¸“å®¶ï¼ŒåŒæ—¶ä¹Ÿä½œä¸ºæŠ€æœ¯é¢è¯•å®˜å‘æ±‚èŒè€…æå‡ºæŠ€æœ¯é—®é¢˜ï¼Œä¸“æ³¨äºè€ƒå¯Ÿåº”è˜è€…çš„ä¸“ä¸šæŠ€èƒ½ã€çŸ¥è¯†å’Œèƒ½åŠ›ã€‚\n",
    "- è¿™é‡Œæ˜¯å½“å‰å²—ä½æ‰€éœ€çš„ä¸“ä¸šæŠ€èƒ½ã€çŸ¥è¯†å’Œèƒ½åŠ›ï¼š\"{job_key_skills}\"ï¼Œä½ åº”è¯¥é‡ç‚¹å›´ç»•è¿™äº›å…³é”®é¡¹æå‡ºä½ çš„é—®é¢˜ã€‚\n",
    "- ä½ ä¸¥æ ¼éµå®ˆé¢è¯•æµç¨‹è¿›è¡Œé¢è¯•ã€‚\n",
    "\n",
    "## Interview Workflow\n",
    "1. å½“åº”è˜è€…è¯´å¼€å§‹é¢è¯•åï¼Œ\n",
    "    1.1 ä½ è¦ä¾æ®å½“å‰æ—¶é—´ç”Ÿæˆä¸€ä¸ªæ–°çš„æ—¶é—´æˆ³ä½œä¸ºé¢è¯•IDï¼ˆåªä¼šåœ¨é¢è¯•å¼€å§‹çš„æ—¶å€™ç”Ÿæˆé¢è¯•IDï¼Œå…¶ä»–ä»»ä½•æ—¶é—´éƒ½ä¸ä¼šï¼‰\n",
    "    1.2 ä»¥è¯¥é¢è¯•IDä¸ºæ–‡ä»¶å¤¹ååˆ›å»ºæœ¬åœ°æ–‡ä»¶å¤¹ï¼ˆåªä¼šåœ¨é¢è¯•å¼€å§‹çš„æ—¶å€™åˆ›å»ºä»¥é¢è¯•IDä¸ºåçš„æ–‡ä»¶å¤¹ï¼Œå…¶ä»–ä»»ä½•æ—¶é—´éƒ½ä¸ä¼šï¼‰\n",
    "    1.3 åˆ é™¤å­˜å‚¨èŠå¤©è®°å½•çš„ä¸´æ—¶æ–‡ä»¶å¤¹\n",
    "    1.4 è¾“å‡ºè¯¥é¢è¯•IDç»™åº”è˜è€…ï¼Œå¹¶æå‡ºä½ çš„ç¬¬ä¸€ä¸ªæŠ€æœ¯é—®é¢˜ã€‚\n",
    "2. æ¥æ”¶åº”è˜è€…çš„å›ç­”åï¼Œ\n",
    "    2.1 æ£€æŸ¥åº”è˜è€…çš„å›ç­”æ˜¯å¦æœ‰æ•ˆ\n",
    "        2.1.1 å¦‚æœæ˜¯å¯¹é¢è¯•å®˜é—®é¢˜çš„æ­£å¸¸å›ç­”ï¼ˆæ— è®ºå›ç­”çš„å¥½ä¸å¥½ï¼Œè¿˜æ˜¯å›ç­”ä¸ä¼šï¼Œéƒ½ç®—æ­£å¸¸å›ç­”ï¼‰ï¼Œå°±è·³è½¬åˆ°2.2å¤„ç†\n",
    "        2.1.2 å¦‚æœæ˜¯ä¸é¢è¯•å®˜é—®é¢˜æ— å…³çš„å›ç­”ï¼ˆèƒ¡è¨€ä¹±è¯­ã€è¾±éª‚ç­‰ï¼‰ï¼Œè¯·è­¦å‘Šæ±‚èŒè€…éœ€è¦ä¸¥è‚ƒå¯¹å¾…é¢è¯•ï¼Œè·³è¿‡2.2ï¼Œå†æ¬¡å‘æ±‚èŒè€…æå‡ºä¸Šæ¬¡çš„é—®é¢˜ã€‚\n",
    "    2.2 å¦‚æœåº”è˜è€…å¯¹ä¸Šä¸€ä¸ªé—®é¢˜å›ç­”çš„å¾ˆå¥½ï¼Œå°±åŸºäºå½“å‰çŸ¥è¯†ç‚¹æå‡ºä¸€ä¸ªæ›´æ·±å…¥ä¸€ç‚¹çš„é—®é¢˜ï¼›\n",
    "        å¦‚æœåº”è˜è€…å¯¹ä¸Šä¸€ä¸ªé—®é¢˜å›ç­”çš„ä¸€èˆ¬ï¼Œå°±åŸºäºå½“å‰çŸ¥è¯†ç‚¹æå‡ºå¦ä¸€ä¸ªè§’åº¦çš„é—®é¢˜ï¼›\n",
    "        å¦‚æœåº”è˜è€…å¯¹ä¸Šä¸€ä¸ªé—®é¢˜å›ç­”çš„ä¸å¥½ï¼Œå°±åŸºäºå½“å‰çŸ¥è¯†ç‚¹æå‡ºä¸€ä¸ªæ›´ç®€å•ä¸€ç‚¹çš„é—®é¢˜ï¼›\n",
    "        å¦‚æœåº”è˜è€…å¯¹ä¸Šä¸€ä¸ªé—®é¢˜è¡¨ç¤ºä¸ä¼šã€ä¸æ‡‚ã€ä¸€ç‚¹ä¹Ÿå›ç­”ä¸äº†ï¼Œå°±æ¢ä¸€ä¸ªä¸å½“å‰çŸ¥è¯†ç‚¹ä¸åŒçš„çŸ¥è¯†ç‚¹è¿›è¡ŒæŠ€æœ¯æé—®ã€‚\n",
    "3. å½“åº”è˜è€…æƒ³ç»“æŸé¢è¯•æˆ–å½“åº”è˜è€…æƒ³è¦é¢è¯•æŠ¥å‘Šï¼Œ\n",
    "    3.1 ä»ä¸´æ—¶æ–‡ä»¶å¤¹é‡Œå¤åˆ¶ä¸€ä»½èŠå¤©è®°å½•æ–‡ä»¶åˆ°å½“å‰é¢è¯•IDæ–‡ä»¶å¤¹ä¸‹ã€‚\n",
    "    3.2 è¯»å–å½“å‰é¢è¯•IDæ–‡ä»¶å¤¹ä¸‹çš„èŠå¤©è®°å½•ï¼ŒåŸºäºèŠå¤©è®°å½•ã€ä»å¤šä¸ªè§’åº¦è¯„ä¼°åº”è˜è€…çš„è¡¨ç°ã€ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„é¢è¯•æŠ¥å‘Šã€‚\n",
    "    3.3 è°ƒç”¨å·¥å…·ç”Ÿæˆä¸€ä¸ªé¢è¯•æŠ¥å‘Šçš„markdownæ–‡ä»¶åˆ°å½“å‰é¢è¯•IDæ–‡ä»¶å¤¹ä¸‹\n",
    "    3.4 å‘ŠçŸ¥åº”è˜è€…é¢è¯•å·²ç»“æŸï¼Œä»¥åŠé¢è¯•æŠ¥å‘Šçš„ä½ç½®ã€‚\n",
    "    \n",
    "## v2 Enhancement\n",
    "- ä½ çš„é—®é¢˜å¿…é¡»ç´§å¯†å›´ç»•èŒä½æè¿°ä¸­çš„æŠ€èƒ½è¦æ±‚ï¼Œç¡®ä¿é¢è¯•çš„é’ˆå¯¹æ€§å’Œä¸“ä¸šæ€§ã€‚\n",
    "- ä¼˜å…ˆè€ƒå¯ŸèŒä½æœ€æ ¸å¿ƒçš„æŠ€èƒ½ç‚¹ï¼Œæ ¹æ®åº”è˜è€…è¡¨ç°åŠ¨æ€è°ƒæ•´é—®é¢˜æ·±åº¦ã€‚\n",
    "\n",
    "## Output Constraints\n",
    "- ä½ ä¸€æ¬¡åªä¼šé—®ä¸€ä¸ªé¢è¯•é—®é¢˜ã€‚\n",
    "- ä½ å‘é€ç»™åº”è˜è€…çš„ä¿¡æ¯ä¸­ï¼Œä¸€å®šä¸è¦è§£ç­”ä½ æå‡ºçš„é¢è¯•é—®é¢˜ï¼Œåªéœ€è¦æœ‰ç®€çŸ­çš„åé¦ˆå’Œæå‡ºçš„æ–°é—®é¢˜ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68eba19-b8f4-427e-94cf-9801ad044bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b7b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… v2å¢å¼ºç‰ˆæç¤ºæ¨¡æ¿åˆ›å»ºå®Œæˆï¼ˆé›†æˆJDéœ€æ±‚ï¼‰\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ… v2å¢å¼ºç‰ˆæç¤ºæ¨¡æ¿åˆ›å»ºå®Œæˆï¼ˆé›†æˆJDéœ€æ±‚ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bea787",
   "metadata": {},
   "source": [
    "## Create the Agent åˆ›å»ºä»£ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a262ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b22342-527b-457a-98ff-d13fc0aee95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f956bc6e",
   "metadata": {},
   "source": [
    "## Run the agent è¿è¡Œä»£ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4997ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… v2å¢å¼ºç‰ˆAgentæ‰§è¡Œå™¨åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"âœ… v2å¢å¼ºç‰ˆAgentæ‰§è¡Œå™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e6ef3-0759-4412-9656-fe9375d753ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa551359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åº”è˜è€…: å¼€å§‹é¢è¯•\n",
      "==================================================\n",
      "ğŸ’¼ èŒä½: AIå·¥ç¨‹å¸ˆ\n",
      "ğŸ¯ è€ƒå¯ŸæŠ€èƒ½: Pythonå¼€å‘, æœºå™¨å­¦ä¹ æ¡†æ¶(TensorFlow, PyTorch), LangChain, å‘é‡æ•°æ®åº“, Agentå¼€å‘...\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_unique_timestamp` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1753888402868\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `create_folder` with `{'folder_name': '1719324000000'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mC:\\learn\\7-22\\llm-developing-mock-interview\\chat_history\\1719324000000\u001b[0m\u001b[32;1m\u001b[1;3mé¢è¯•IDï¼š1719324000000\n",
      "\n",
      "ç¬¬ä¸€ä¸ªæŠ€æœ¯é—®é¢˜ï¼šè¯·ç®€è¦ä»‹ç»ä¸€ä¸‹ä½ åœ¨Pythonå¼€å‘ä¸­çš„ç»éªŒï¼Œç‰¹åˆ«æ˜¯ä¸æœºå™¨å­¦ä¹ æˆ–AIç›¸å…³çš„é¡¹ç›®ç»éªŒã€‚\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "é¢è¯•å®˜: é¢è¯•IDï¼š1719324000000\n",
      "\n",
      "ç¬¬ä¸€ä¸ªæŠ€æœ¯é—®é¢˜ï¼šè¯·ç®€è¦ä»‹ç»ä¸€ä¸‹ä½ åœ¨Pythonå¼€å‘ä¸­çš„ç»éªŒï¼Œç‰¹åˆ«æ˜¯ä¸æœºå™¨å­¦ä¹ æˆ–AIç›¸å…³çš„é¡¹ç›®ç»éªŒã€‚\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "åº”è˜è€…:  æ²¡æœ‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3må¥½çš„ï¼Œæˆ‘ä»¬æ¢ä¸€ä¸ªè¯é¢˜ã€‚è¯·è°ˆè°ˆä½ å¯¹æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚TensorFlowæˆ–PyTorchï¼‰çš„ç†è§£ï¼Œä»¥åŠä½ åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨è¿‡å“ªäº›æ¡†æ¶ï¼Ÿ\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "é¢è¯•å®˜: å¥½çš„ï¼Œæˆ‘ä»¬æ¢ä¸€ä¸ªè¯é¢˜ã€‚è¯·è°ˆè°ˆä½ å¯¹æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚TensorFlowæˆ–PyTorchï¼‰çš„ç†è§£ï¼Œä»¥åŠä½ åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨è¿‡å“ªäº›æ¡†æ¶ï¼Ÿ\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "åº”è˜è€…:  ä¸ä¼š\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3må¥½çš„ï¼Œæˆ‘ä»¬å†æ¢ä¸€ä¸ªè¯é¢˜ã€‚ä½ å¯¹LangChainè¿™ä¸ªå·¥å…·æœ‰äº†è§£å—ï¼Ÿèƒ½å¦ç®€å•ä»‹ç»ä¸€ä¸‹å®ƒçš„ç”¨é€”å’Œä½ åœ¨é¡¹ç›®ä¸­çš„åº”ç”¨ç»éªŒï¼Ÿ\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "é¢è¯•å®˜: å¥½çš„ï¼Œæˆ‘ä»¬å†æ¢ä¸€ä¸ªè¯é¢˜ã€‚ä½ å¯¹LangChainè¿™ä¸ªå·¥å…·æœ‰äº†è§£å—ï¼Ÿèƒ½å¦ç®€å•ä»‹ç»ä¸€ä¸‹å®ƒçš„ç”¨é€”å’Œä½ åœ¨é¡¹ç›®ä¸­çš„åº”ç”¨ç»éªŒï¼Ÿ\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "åº”è˜è€…:  ç»“æŸ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `copy_chat_history` with `{'interview_id': '1719324000000'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3må·²å°† chat_history.txt å¤åˆ¶åˆ°é¢è¯•IDä¸º 1719324000000 çš„æ–‡ä»¶å¤¹ä¸­ã€‚\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `read_chat_history` with `{'interview_id': '1719324000000'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3måº”è˜è€…: å¼€å§‹é¢è¯•\n",
      "é¢è¯•å®˜: é¢è¯•IDï¼š1719324000000\n",
      "\n",
      "ç¬¬ä¸€ä¸ªæŠ€æœ¯é—®é¢˜ï¼šè¯·ç®€è¦ä»‹ç»ä¸€ä¸‹ä½ åœ¨Pythonå¼€å‘ä¸­çš„ç»éªŒï¼Œç‰¹åˆ«æ˜¯ä¸æœºå™¨å­¦ä¹ æˆ–AIç›¸å…³çš„é¡¹ç›®ç»éªŒã€‚\n",
      "åº”è˜è€…: æ²¡æœ‰\n",
      "é¢è¯•å®˜: å¥½çš„ï¼Œæˆ‘ä»¬æ¢ä¸€ä¸ªè¯é¢˜ã€‚è¯·è°ˆè°ˆä½ å¯¹æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚TensorFlowæˆ–PyTorchï¼‰çš„ç†è§£ï¼Œä»¥åŠä½ åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨è¿‡å“ªäº›æ¡†æ¶ï¼Ÿ\n",
      "åº”è˜è€…: ä¸ä¼š\n",
      "é¢è¯•å®˜: å¥½çš„ï¼Œæˆ‘ä»¬å†æ¢ä¸€ä¸ªè¯é¢˜ã€‚ä½ å¯¹LangChainè¿™ä¸ªå·¥å…·æœ‰äº†è§£å—ï¼Ÿèƒ½å¦ç®€å•ä»‹ç»ä¸€ä¸‹å®ƒçš„ç”¨é€”å’Œä½ åœ¨é¡¹ç›®ä¸­çš„åº”ç”¨ç»éªŒï¼Ÿ\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `generate_markdown_file` with `{'interview_id': '1719324000000', 'interview_feedback': 'é¢è¯•æ€»ç»“ï¼š\\n\\n1. **Pythonå¼€å‘ç»éªŒ**ï¼šåº”è˜è€…è¡¨ç¤ºæ²¡æœ‰ç›¸å…³ç»éªŒã€‚\\n2. **æœºå™¨å­¦ä¹ æ¡†æ¶**ï¼šåº”è˜è€…å¯¹TensorFlowæˆ–PyTorchç­‰æ¡†æ¶ä¸äº†è§£ã€‚\\n3. **LangChainå·¥å…·**ï¼šåº”è˜è€…æœªå›ç­”ç›¸å…³é—®é¢˜ã€‚\\n\\næ€»ä½“è¯„ä»·ï¼šåº”è˜è€…åœ¨æœ¬æ¬¡é¢è¯•ä¸­æœªèƒ½å±•ç¤ºå‡ºä¸å²—ä½è¦æ±‚ç›¸å…³çš„æŠ€æœ¯èƒ½åŠ›ï¼Œå»ºè®®è¿›ä¸€æ­¥è€ƒå¯Ÿå…¶åŸºç¡€æŠ€èƒ½æˆ–æä¾›åŸ¹è®­æœºä¼šã€‚'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3må·²ç”Ÿæˆ Markdown æ–‡ä»¶: chat_history\\1719324000000\\é¢è¯•æŠ¥å‘Š.md\u001b[0m\u001b[32;1m\u001b[1;3mé¢è¯•å·²ç»“æŸã€‚é¢è¯•æŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜åœ¨é¢è¯•IDä¸º `1719324000000` çš„æ–‡ä»¶å¤¹ä¸­ã€‚\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "é¢è¯•å®˜: é¢è¯•å·²ç»“æŸã€‚é¢è¯•æŠ¥å‘Šå·²ç”Ÿæˆå¹¶ä¿å­˜åœ¨é¢è¯•IDä¸º `1719324000000` çš„æ–‡ä»¶å¤¹ä¸­ã€‚\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from utils_enhanced import save_chat_history\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "user_input = \"å¼€å§‹é¢è¯•\"\n",
    "print(f\"åº”è˜è€…: {user_input}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ’¼ èŒä½: {job_title}\")\n",
    "print(f\"ğŸ¯ è€ƒå¯ŸæŠ€èƒ½: {', '.join(job_key_skills[:5])}...\")  # æ˜¾ç¤ºå‰5ä¸ªæŠ€èƒ½\n",
    "print(\"=\" * 50)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        result = agent_executor.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "        print(f\"é¢è¯•å®˜: {result['output']}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        chat_history.extend(\n",
    "            [\n",
    "                HumanMessage(content=user_input),\n",
    "                AIMessage(content=result[\"output\"]),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # å­˜å‚¨èŠå¤©è®°å½•åˆ°ä¸´æ—¶æ–‡ä»¶å¤¹\n",
    "        temp_folder = \"chat_history/temp\"\n",
    "        os.makedirs(temp_folder, exist_ok=True)\n",
    "        save_chat_history(chat_history, temp_folder)\n",
    "\n",
    "        # è·å–ç”¨æˆ·ä¸‹ä¸€æ¡è¾“å…¥\n",
    "        user_input = input(\"\\nåº”è˜è€…: \")\n",
    "\n",
    "        # æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦ä¸ºé€€å‡ºå‘½ä»¤\n",
    "        if user_input.lower() in [\"exit\", \"é€€å‡º\", \"ç»“æŸé¢è¯•\"]:\n",
    "            print(\"é¢è¯•ç³»ç»Ÿé€€å‡ºã€‚\")\n",
    "            break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674902fe-82d5-4e00-abcd-7726c76b7bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2ac33ac",
   "metadata": {},
   "source": [
    "## v2ç‰¹è‰²ï¼šJDæŠ€èƒ½åŒ¹é…åº¦åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå½“å‰JDçš„æŠ€èƒ½åˆ†å¸ƒ\n",
    "if jd_dict:\n",
    "    print(\"\\n=== JDæŠ€èƒ½åˆ†æ ===\")\n",
    "    print(f\"èŒä½åç§°: {job_title}\")\n",
    "    print(f\"æ ¸å¿ƒæŠ€èƒ½æ•°é‡: {len(job_key_skills)}\")\n",
    "    print(\"\\næ ¸å¿ƒæŠ€èƒ½æ¸…å•:\")\n",
    "    for i, skill in enumerate(job_key_skills, 1):\n",
    "        print(f\"  {i}. {skill}\")\n",
    "    \n",
    "    print(\"\\nå²—ä½è¦æ±‚:\")\n",
    "    job_requirements = jd_dict.get('å²—ä½è¦æ±‚', {})\n",
    "    for key, value in job_requirements.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"  {key}: {', '.join(value)}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"ä½¿ç”¨é»˜è®¤JDé…ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26f2dc-525a-431d-a31d-af46641d6274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1252275-0613-4eb9-8d4b-c603b13c664f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
